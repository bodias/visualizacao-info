{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de redução de dimensionalidade\n",
    "\n",
    "Na era do Big Data, os dados não só estão se tornando cada vez maiores como também mais complexos. Isso se traduz em um aumento espetacular da dimensionalidade dos dados. Por exemplo, a dimensionalidade de um conjunto de imagens é o número de pixels que ela contém, que pode variar de milhares a milhões.\n",
    "\n",
    "Computacionalmente não existe problema em processar tantas dimensões, no entanto, nós humanos somos limitados a três dimensões. Dessa forma, precisamos de maneiras para visualizar dados com alta dimensionalidade para avalia-los antes de usar como entrada para algum outro processo/algorítmo, como Machine Learning por exemplo.\n",
    "\n",
    "### Como podemos reduzir a dimensionalidade de um dataset de um número arbitrário para dois ou três, que é o que costumamos fazer para visualizar dados em uma tela?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogia : Fotografia\n",
    "\n",
    "A resposta pode ser melhor entendida com uma implementação real de redução de dimensionalidade : a **câmera fotográfica**\n",
    "\n",
    "<img src='photo_example.jpg' height=\"382\" width=\"574\">\n",
    "\n",
    "A camera fotográfica, por meio da fotografia, representa uma projeção de um espaço multidimensional (mundo real) em um plano (foto). As características originais do espaço de alta dimensionalidade são mantidos na nova projeção com baixa dimensionalidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset\n",
    "\n",
    "Para esse exercício utilizaremos o dataset MNIST (http://yann.lecun.com/exdb/mnist/) que consiste em 70.000 imagens de dígitos de 0 a 9 escritos a mão.\n",
    "\n",
    "Não precisamos realizar o download do dataset manualmente, podemos baixá-lo através do Scikit learn, utilizando o comando ***fetch_mldata(\"MNIST original\")***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import das bibliotecas básicas utilizadas neste trabalho\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "X = mnist.data / 255.0\n",
    "y = mnist.target\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar a manipulação dos dados, vamos converter a matriz original em um DataFrame do Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df['label'] = y\n",
    "df['label'] = df['label'].apply(lambda i: str(i))\n",
    "\n",
    "X, y = None, None\n",
    "\n",
    "print('Tamanho do dataframe: {}'.format(df.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já que não queremos utilizar todos os 70.000 dígitos do dataset em alguns cálculos, nós vamos extrair uma amostra aleatória dos dados. A \"randomização\" é importante pois o dataset original está ordenado por rótulo (ex.: as primeiras 7 mil imagens são zeros, e assim por diante). Para garantir essa aleatoriedade, vamos utilizar uma função do numpy chamada ***np.random.permutation***, utilizando um número entre 0 e 69.999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndperm = np.random.permutation(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos um DataFrame e um vetor com índices randomizados. Primeiro, vamos verificar como os dados do dataset se parecem, selecionando 30 imagens aleatórias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plota o gráfico\n",
    "plt.gray()\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,30):\n",
    "    ax = fig.add_subplot(3,10,i+1, title='Digit: ' + str(df.loc[rndperm[i],'label']) )\n",
    "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens estão todas no formato 28x28 píxels, portanto temos um total de 784 dimensões (28x28=784), cada uma contendo o valor de um píxel específico.\n",
    "\n",
    "O que podemos fazer é reduzir o número de dimensões drasticamente enquanto tentamos reter a maior 'variação' da informação possível. Isto é o que chamamos de **redução de dimensionalidade**. \n",
    "\n",
    "Primeiro, vamos utilizar um conceito mais simples, conhecido como Principal Component Analysis (**PCA**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de dimensionalidade utilizando PCA\n",
    "\n",
    "PCA é uma técnica para redução do número de dimensões em um dataset retendo maior parte da informação. Ela usa a correlação entre algumas dimensões e tenta prover um número mínimo de variáveis que mantém a maior quantidade de variação da informação sobre como os dados estão originalmente distribuídos. \n",
    "\n",
    "Não vamos descer ao detalhe de como são calculados os componentes principais do PCA, mas esse link [aqui](https://www.math.hmc.edu/calculus/tutorials/eigenstuff/) aborda como eles são calculados. \n",
    "\n",
    "Já que nós humanos gostamos de plots 2/3D, vamos começar gerando os três primeiros componentes principais a partir das 784 dimensões originais. Nós vamos ver quanto da variação total do dataset cada componente é responsável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "\n",
    "df['pca-um'] = pca_result[:,0]\n",
    "df['pca-dois'] = pca_result[:,1] \n",
    "df['pca-tres'] = pca_result[:,2]\n",
    "\n",
    "print('Variação explicada por cada componente : {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, dado que os dois primeiros componentes são responsáveis por cerca de 17% da variação em todo o dataset, vamos ver se isso é suficiente para separar cada dígito visualmente. O que faremos é criar um scatterplot do primeiro e segundo componente principal e colorir cada um dos diferentes dígitos com uma cor diferente. Se tivermos sorte os dígitos estarão posicionados juntos (clusterizados), o que significaria que os dois principais componentes realmente representam uma boa projeção dos dígitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a figura\n",
    "fig = plt.figure( figsize=(8,8) )\n",
    "ax = fig.add_subplot(1, 1, 1, title='PCA' )\n",
    "# Cria o scatterplot\n",
    "ax.scatter(\n",
    "    x=df['pca-um'], \n",
    "    y=df['pca-dois'], \n",
    "    c=df['label'], \n",
    "    cmap=plt.cm.get_cmap('Paired'), \n",
    "    alpha=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do gráfico nós podemos ver que os dois componentes definitivamente contém alguma informação, especialmente para alguns dígitos, mas claramente não são suficientes para separar todo o dataset. Abaixo veremos um pouco sobre uma outra técnica e exploraremos se ela pode nos dar uma melhor maneira de reduzir a dimensionalidade para visualização. O método que vamos explorar é conhecido como t-SNE (t-Distributed Stochastic Neighbouring Entities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "\n",
    "Esse material é uma introdução a um algorítmo popular de redução de dimensionalidade : t-distributed stochastic neighbor embedding (**t-SNE**). Desenvolvido por Laurens van der Maaten e Geoffrey Hinton ([link para o artigo original](https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf)), este algorítmo tem sido aplicado com sucesso em vários conjuntos de dados. Aqui, vamos focar na aplicação da técnica utilizando Python e a biblioteca scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "#para efeitos de demonstração limitaremos os dados a uma amostra de n_sne valores aleatórios.\n",
    "n_sne = 7000\n",
    "\n",
    "time_start = time.time()\n",
    "tsne = TSNE(random_state=42, verbose=1)\n",
    "tsne_results = tsne.fit_transform(df.loc[rndperm[:n_sne],feat_cols].values)\n",
    "\n",
    "print('t-SNE pronto! Tempo decorrido: {} segundos'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = df.loc[rndperm[:n_sne],:].copy()\n",
    "df_tsne['x-tsne'] = tsne_results[:,0]\n",
    "df_tsne['y-tsne'] = tsne_results[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos as duas dimensões resultantes do processo de redução de dimensionalidade pelo t-SNE, podemos novamente visualizar o resultado através de um scatterplot com as duas dimensões nos eixos x e y, e colorindo cada dígito de acordo com seu label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a figura\n",
    "fig = plt.figure( figsize=(8,8) )\n",
    "ax = fig.add_subplot(1, 1, 1, title='tSNE' )\n",
    "# Cria o scatterplot\n",
    "ax.scatter(\n",
    "    x=df_tsne['x-tsne'], \n",
    "    y=df_tsne['y-tsne'], \n",
    "    c=df_tsne['label'], \n",
    "    cmap=plt.cm.get_cmap('Paired'), \n",
    "    alpha=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado trás uma melhoria significativa sobre o PCA utilizado anteriormente. Podemos ver que os dígitos estão claramente agrupados no seu próprio grupo.\n",
    "\n",
    "Porém, vamos trabalhar o gráfico para melhor visualizar cada cluster e seu label correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn para incrementar um pouco os gráficos :D\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as PathEffects\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "sns.set_context(\"notebook\", font_scale=1.5,\n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "def scatter(x, y):\n",
    "    palette = np.array(sns.color_palette(\"hls\", 10))\n",
    "\n",
    "    # Criamos o scatterplot.\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40,\n",
    "                    c=palette[y.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')\n",
    "\n",
    "    # Adicionamos o label de cada dígito no centro de cada cluster\n",
    "    txts = []\n",
    "    for i in range(10):\n",
    "        # Position of each label.\n",
    "        xtext, ytext = np.median(x[y == i, :], axis=0)\n",
    "        txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "        txt.set_path_effects([\n",
    "            PathEffects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "            PathEffects.Normal()])\n",
    "        txts.append(txt)\n",
    "\n",
    "    return f, ax, sc, txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(tsne_results, pd.to_numeric(df.loc[rndperm[:n_sne],'label']).values.astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente vemos que alguns dígitos estão com sobreposição.\n",
    "\n",
    "Existe uma recomendação que diz que, em caso de dados com dimensionalidade muito alta, devemos aplicar uma outra técnica de redução de dimensionalidade antes de usar o t-SNE.\n",
    "\n",
    "Seguindo essa recomendação, vamos usar PCA novamente. Primeiro criaremos um novo dataset contendo 50 dimensões geradas pela redução via PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : gerar PCA para os 50 primeiros principais componentes\n",
    "pca_50 = None\n",
    "pca_result_50 = None\n",
    "\n",
    "print('Variação explicada pelos 50 componentes principais: {}'.format(np.sum(pca_50.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Os primeiros 50 componentes explicam cerca de 82% da variação total nos dados.\n",
    "\n",
    "Agora, vamos tentar utilizar esses componentes como entrada para o t-SNE. Desta vez utilizaremos uma amostra de 10.000 para não sobrecarregar demais a memória e o processador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sne = 10000\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "#TODO : Executar o t-SNE sobre as 50 features extraídas pelo PCA\n",
    "tsne = None\n",
    "tsne_pca_results = None\n",
    "\n",
    "print('t-SNE pronto! Tempo decorrido: {} segundos'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(tsne_pca_results, pd.to_numeric(df.loc[rndperm[:n_sne],'label']).values.astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "Após seguir a recomendação e realizar primeiro a redução de dimensionalidade via PCA, reduzindo para 50 features, e depois via t-SNE, quais foram as melhorias percebidas?\n",
    "\n",
    "*descreva a diferença entre o plot anterior gerado utilizando as 784 features e o plot acima.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
